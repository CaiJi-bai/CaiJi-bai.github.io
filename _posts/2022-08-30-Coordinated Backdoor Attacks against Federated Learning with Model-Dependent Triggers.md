---
layout: mypost
title: Coordinated Backdoor Attacks against Federated Learning with Model-Dependent Triggers
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>Coordinated Backdoor Attacks against Federated Learning with Model-Dependent Triggers</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>使用模型依赖触发器针对联邦学习进行协同后门攻击</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Xueluan Gong, Yanjiao Chen, Huayang Huang, Yuqing Liao, Shuai Wang, Qian Wang</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>IEEE Network, Volume 36 [SCI 1 区]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2022 年 3 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>单个后门触发器的影响很快就会被后续的良性更新所冲淡</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td></td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>模型依赖触发器</td>
    </tr>
</table>

# 内容总结

# 主要贡献

1. 使用多个本地后门触发器设计了针对联邦学习的有效后门攻击，实现了高攻击成功率和主要任务准确性。 
2. 将提出的攻击与三个基线进行比较，包括单触发攻击（例如，使用随机或模型相关的触发器）和协调触发攻击（例如，使用随机触发器）。

# 预备知识

### 随机触发器

随机触发器是独立于学习模型生成的。例如，徽标，贴纸或像素扰动。由于随机触发器与模型训练过程不相关，因此我们发现其在触发后门模型的后门方面的能力较弱，尤其是在聚合过程中局部模型被稀释的联邦学习中。

### 模型依赖触发器

模型依赖触发器被设计成最大限度地激活学习模型内的某些神经元。我们发现全局模型更有可能记住聚合后的触发器。

# 威胁模型

1. 攻击者管理本地训练过程，包括配置步长、学习率和 epoch 数的参数。 
2. 攻击者无法访问中央服务器的聚合过程，也无法影响诚实最终用户的训练过程。 
3. 假设负责模型聚合的中央服务器是诚实的，不会泄露或篡改用户的训练数据集。
4. 所有参与者都忠实地遵循联邦学习协议。

# 攻击方法

### 概述

本文提出了一种使用模型依赖触发器针对联邦学习的优化的协调后门攻击。它包括两个主要步骤：模型依赖局部触发器的生成和协调后门注入。

![联邦学习中协同后门攻击的概述](联邦学习中协同后门攻击的概述.png)

### 模型依赖局部触发器的生成

1. 确定触发器的结构，包括其形状，大小和位置。
2. 当模型接近收敛时，每个恶意用户端构建触发器掩码 `$M$`。`$M$` 是一个布尔值矩阵，与模型的输入具有相同的维数。对于输入数据，掩模 `$M$` 将触发器区域初始化为随机值，其他部分初始化为 0。触发器生成过程相当于寻找掩码的最优值赋值的过程。
3. 将标签是目标标签的大量数据样本输入到模型中，在神经网络中选择一层，并记录所选层中每个神经元的激活数量，最终选择激活次数和到下一层的权重值总和最大的神经元。
4. 对于选定的神经元，定义一个损失函数，为当前神经元的值与其目标值之间的均方误差，并使用梯度下降法使得损失函数最小化，其中目标值为所选层中神经元的最大值。
5. 在最后一轮迭代之后，从掩码中提取触发器。

### 协调后门注入

1. 生成局部触发器后，恶意客户端对本地训练数据进行投毒。
2. 恶意客户端使用中毒的数据集将接收到的全局模型从选定层重新训练到输出层，获得后门局部模型。
3. 为了增强攻击能力，恶意客户端需要在向服务器提交本轮更新之前，放大恶意更新参数。其中放大因子的选择需要在主任务准确率与攻击成功率之间进行权衡。
4. 上述过程投毒过程将重复多次，直到全局模型收敛。
5. 最后，恶意客户端可以使用他们的本地触发器或由本地触发器组成的全局触发器来触发嵌入在全局模型中的后门。

关键：确定毒化间隔，即两次毒化过程之间的轮次间隔。

如果中毒间隔太长，攻击成功率会降低，因为早期注入的局部触发器可能会被全局模型遗忘。

# 实验

+ 数据集：MNIST 和 CIFAR-10
+ 数据分布；no-iid
+ 训练模型：LeNet 和 ResNet-18
+ 基线算法：（1）使用随机触发器的协调攻击（DBA）（2）使用模型依赖全局触发器的单触发器后门攻击（3）使用随机全局触发器的单触发器后门攻击

### 实验结果

![实验结果](实验结果.png)

![对拜占庭弹性聚合方法的鲁棒性](对拜占庭弹性聚合方法的鲁棒性.png)

# 结论

在本文中，我们通过嵌入模型相关的后门触发器，提出了一种针对联邦学习的有效协同后门攻击。 我们可以成功地对全局模型进行后门攻击，即使后门在联邦学习过程中被聚合稀释。 在 MNIST 和 CIFAR-10 上进行的广泛比较实验证实了我们的攻击在保持主要任务准确性的同时实现更高攻击成功率的有效性和持久性。 更重要的是，我们证明了拜占庭弹性聚合方法对我们提出的攻击并不稳健。

# 参考

1. [Trojaning Attack on Neural Networks](https://blog.csdn.net/qq_41409438/article/details/103411986){:target="_blank"}