---
layout: mypost
title: FederatedReverse_A Detection and Defense Method Against Backdoor Attacks in Federated Learning
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>FederatedReverse: A Detection and Defense Method Against Backdoor Attacks in Federated Learning</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>FederatedReverse：一种针对联邦学习中后门攻击的检测和防御方法</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Chen Zhao, Yu Wen, Shuailou Li, Fucheng Liu, Dan Meng</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>9th IH&MMSec 2021: Virtual Event, Belgium [CCF 网络与信息安全 C 类会议]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2021 年 6 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>大多数后门防御技术不适用于联邦学习，因为它们基于在联邦学习方案中无法保存的整个数据样本。新提出的联邦学习方法牺牲了模型的准确性，并且一旦攻击在许多训练回合中持续存在，仍然失败。</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td></td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>逆向工程、全局反向触发器生成、异常值检测和模型修复</td>
    </tr>
</table>

# 内容总结

# 主要贡献

1. 在不违背联邦学习设计原则的前提下，我们提出了一种在联邦学习中检测和防御后门攻击的有效方法FederatedReverse。
2. 我们的解决方案降低了联邦学习中后门攻击的成功率，同时保持了主任务的准确性。
3. 我们在多个图像识别任务上实现并验证了所提出的解决方案，例如手写数字识别和道路交通标志识别任务。通过与现有的联邦学习防御方法进行比较，证明了我们的方案在防御联邦学习后门攻击方面具有更好的性能。

# 威胁模型

### 对手目标

通过向中央服务器提交本地恶意模型更新，将后门注入全局模型。受污染的模型将对带有触发器的输入进行错误分类，但会正确标记剩余的输入。

### 对手的能力

攻击者可以完全控制联邦学习中的一个或多个参与者。 攻击者还可以控制受感染参与者的本地数据、本地训练过程以及提交给中央服务器的模型更新。 但是，攻击者无法访问用于更新全局模型的联邦学习聚合算法，也无法控制其他良性参与者的训练过程。

### 防御目标

我们旨在提出一种针对联邦学习中现有后门攻击 (尤其是模型替换攻击和分布式后门攻击) 的检测和防御方法。该方法可以在联邦学习训练过程中检测全局模型是否受到攻击，并在不影响主要任务准确性的情况下降低后门攻击的成功率。

### 防御者的能力

防御者无法直接访问每个参与者提交的参与者数据和模型更新。 否则，防御者将违反联邦学习的设计原则，导致用户隐私数据泄露。


# 方法

### 概述

![FederatedReverse概述](FederatedReverse概述.png)

FederatedReverse 包括逆向工程、全局反向触发器生成、异常值检测和模型修复四个步骤。

### 逆向工程

作用：计算将所有样本识别为指定标签所需添加的最小扰动。

![逆向工程原理](逆向工程原理.png)

### 全局反向触发器生成

1. 每个参与者将本地生成的本地反向触发器发送到中央服务器
2. 服务器需要使用密度聚类算法 DBSCAN 对相同标签不同参与者的本地反向触发器，丢弃与异常值对应的参与者。
3. 使用联邦学习的中央聚合服务器来聚合每个本地触发器，最终获得更鲁棒的全局反向触发器。

### 异常值检测

在获得对应于每个标签的全局反向触发器之后，需要对全局触发器的大小执行离群点检测。

+ 大小：全局反向触发器的 `$\ell_2$` 范数来
+ 离群点检测算法：绝对中值法

![公式10和公式11](公式10和公式11.png)

### 模型修复

方法：遗忘技术

在某轮训练中，将感染标签对应的全局反向触发器添加到干净的训练数据中，但这些数据的标签并没有改变。 在使用这些数据进行训练时，模型会逐渐修改与此触发器相关的权重。 最后，该模型将消除该触发器的影响，实现对后门攻击的防御。

# 实验

+ 数据集：MNIST 和 GTSRB
+ 数据分布：no-iid
+ 训练模型：简单 CNN 网络 和 Resnet-18

![数据集和模型参数](数据集和模型参数.png)

+ 攻击：单发攻击和多发攻击 集中式攻击和分布式攻击
+ 评估指标：攻击成功率 (ASR) 和主要任务准确性。

### 实验结果

**异常值检测**

![异常值检测](异常值检测.png)

**无触发器聚合的异常值检测**

![没有聚合的异常值检测](没有聚合的异常值检测.png)

**FederatedReverse 的防御效果**

![攻击A-M中的攻击成功率](攻击A-M中的攻击成功率.png)

![攻击A-S中的攻击成功率](攻击A-S中的攻击成功率.png)

![攻击A-M中的防御](攻击A-M中的防御.png)

![攻击A-S中的防御](攻击A-S中的防御.png)

![主任务准确率](主任务准确率.png)

**与现有防御方法的比较**

![与现有防御方法的比较](与现有防御方法的比较.png)

# 总结

我们提出了基于逆向工程和鲁棒全局反向触发器的 FederatedReverse 方法，能够有效检测图像识别领域的联邦学习后门攻击，并通过模型修复消除攻击者植入的后门影响。与现有工作相比，我们的方法降低了后门攻击的成功率，同时保证了主要任务的准确性不受影响。 此外，该方法对攻击轮数的增加具有鲁棒性。该方法在联邦学习中四种常见攻击的检测和防御方面取得了可喜的成绩。

# 参考

1. [百度](https://www.baidu.com){:target="_blank"}