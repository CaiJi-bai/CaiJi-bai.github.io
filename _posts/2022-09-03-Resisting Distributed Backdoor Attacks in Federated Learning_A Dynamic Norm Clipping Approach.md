---
layout: mypost
title: Resisting Distributed Backdoor Attacks in Federated Learning_A Dynamic Norm Clipping Approach
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>Resisting Distributed Backdoor Attacks in Federated Learning: A Dynamic Norm Clipping Approach</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>在联邦学习中抵抗分布式后门攻击：一种动态范数裁剪方法</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Yifan Guo, Qianlong Wang, Tianxi Ji, Xufei Wang, Pan Li</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>BigData Conference 2021: Orlando, FL, USA [CCF 交叉/综合/新兴 C 类会议]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2021 年 12 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>最近，范数裁剪方法被开发用来有效防御 FL 中的分布式后门攻击，该攻击不依赖于本地训练数据。然而，我们发现对手仍然可以通过稳健的训练绕过这种防御方案，因为它的范数限制阈值固定的。</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td></td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>动态调整局部更新的范数裁剪阈值</td>
    </tr>
</table>

# 内容总结

# 主要贡献

1. 我们的实验研究表明，固定范数裁剪方案可以被绕过，因为它在训练过程中的固定阈值不能捕捉到全局模型收敛过程中良性局部更新的动态特性。
2. 为了解决这个问题，我们设计了一种新的自适应规范裁剪防御来缓解分布式后门攻击。
3. 我们对我们提出的防御的收敛性进行了理论分析。
4. 在四个公共数据集上的大量实验结果验证了我们提出的方案在缓解分布式后门攻击方面的有效性。特别地，与现有的防御方法相比，我们的动态范数裁剪方法显著降低了84.23% 的攻击成功率。

# 预备知识

![公式1](公式1.png)

![全局模型更新公式](全局模型更新公式.png)

![公式2](公式2.png)

# 一种动态的规范裁剪方法

### 大规模恶意本地更新的必要性。

![CIFAR-10数据集上不同M下ASR与CIA的相关性](CIFAR-10数据集上不同M下ASR与CIA的相关性.png)

### 绕过范数裁剪防御

范数裁剪：在聚合之前限制本地更新的范数，裁剪局部更新以确保其 `$\ell_2$` 范数的上限是一个阈值 `$M$`。

![公式3](公式3.png)

`$M$` 是训练过程的固定吞吐量。选择适当的阈值 `$M$` 对防御的有效性至关重要。

如果 M 设置得太小，就像比局部更新的平均范数小一个阶，即 M = 0.1 · Ei∈nΔw1 i 2，虽然可以限制广泛的恶意更新，但它导致缓慢收敛到最优全局模型，或收敛到次优，

![范数裁剪阈值M太小](范数裁剪阈值M太小.png)

通过简单地增加阈值 M 并在整个训练过程中保持某个 M 不变会带来另一个问题，也就是说，对手可以通过鲁棒训练绕过范数裁剪防御，该训练在每个全局回合中估计 M 足够接近。

可以通过比较任何连续两轮中全局模型的大小来很好地估计它。

![公式4](公式4.png)

![绕过范数裁剪防御](绕过范数裁剪防御.png)

### 收敛时良性局部更新的动态性质

数裁剪方案失败的主要原因是其在训练过程中的固定阈值，无法捕捉到全局模型收敛过程中良性局部更新的动态特性。

![恶意和良性本地更新的统计](恶意和良性本地更新的统计.png)

### 我们的解决方案：动态范数裁剪方法

![算法1](算法1.png)

# 实验

+ 数据集：MNIST[30]、FMNIST[31]、CIFAR-10[32]和Tiny ImageNet[33]
+ 数据分布：no-iid
+ 训练模型：LeNet-5 和 ResNet-18

![实验设置](实验设置.png)

![像素模式后门触发器](像素模式后门触发器.png)

+ 基线模型：
+ 评估指标：攻击成功率（ASR）和干净输入准确度（CIA）

### 实验结果

![性能评估](性能评估.png)

![性能比较1](性能比较1.png)

![性能比较2](性能比较2.png)

![概率阈值的敏感性分析1](概率阈值的敏感性分析1.png)

![概率阈值的敏感性分析2](概率阈值的敏感性分析2.png)

# 总结

在本文中，我们提出了一种新颖的防御方案来抵抗FL中的分布式后门攻击。特别是，我们首先确定导致范数剪切方案失败的主要原因是训练过程中的固定阈值，无法捕获全局模型收敛过程中良性局部更新的动态性质。然后，在此激励下，我们提出了一种新颖的防御措施，以动态调整本地更新的规范剪切阈值。我们还介绍了我们的防御方案的收敛性分析。通过在nonIID设置下对四个公共数据集进行实验，我们发现我们提出的防御可以有效地降低攻击成功率并保持高性能的效用。特别是，与现有防御相比，我们的防御平均降低了84.23% 的攻击成功率。

# 参考

1. [百度](https://www.baidu.com){:target="_blank"}