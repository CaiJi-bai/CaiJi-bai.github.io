---
layout: mypost
title: Can You Really Backdoor Federated Learning?
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>Can You Really Backdoor Federated Learning?</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>你真的可以后门联邦学习吗？</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, H. Brendan McMahan</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>CoRR, November 2019</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2019 年 11 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td></td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td></td>
    </tr>
    <tr>
        <td>创新点</td>
        <td></td>
    </tr>
</table>

# 内容总结  

# 后门攻击场景

+ **对手的抽样**
  + 随机采样攻击：在客户端的随机抽样下，每轮中的对手数量遵循超几何分布。
  + 固定频率攻击：每 f 轮出现一个对手。
+ **后门任务**
  + 在后门攻击中，攻击者的目的是让模型在某些子任务上失败。本文允许非恶意客户端在目标任务中正确标注样本。
  + 本文通过将多个选定的“目标客户机”的示例分组来形成后门任务。将目标客户端的数量称为“后门任务数量”，并探讨其对攻击成功率的影响。

# 模型更新中毒攻击

我们基于 (3; 4) 提出的模型替换范式，重点研究模型更新中毒攻击。当在第 t 轮中仅选择一个攻击者（WLOG假设它是客户端 1）时，攻击者试图通过发送回溯模型 `$\omega^*$` 来替换整个模型
`$$\Delta \omega_t^1 = \beta(\omega^*-\omega_t)$$`
其中 `$\beta$` 是提升系数。

![公式2](公式2.png)

如果我们假设模型已经足够收敛，那么它将在 `$\omega^*$` 的一个小邻域内，因此 k > 1 的其他更新 `$\Delta \omega_t^k$` 很小。如果多个攻击者出现在同一回合中，则假定他们可以相互协调并平均划分此更新。

+ **获取后门模型**
  + 一个描述后门任务的集合 `$D_{mal}$`
  + 一个从真实分布生成的训练样本集合 `$D_{trn}$`
+ **获取后门模型**
  + 不受限制的增强后门攻击：用 `$\omega^t$` 初始化，用 `$D_{mal} \cup D_{trn}$` 训练模型。（更新范数大，作为基线）
  + 范数限制后门攻击：通过使用多轮投影梯度下降训练模型，在每一轮中，我们使用无约束训练策略训练模型，并将其投影回 `$\omega^t$` 周围大小为 `$M/\beta$` 的 `$\ell_2$` 球。

# 防御

+ **更新的规范阈值**

假设对手知道阈值 M，因此总是可以返回这个量级的恶意更新。将这种强大优势赋予对手，使得范数边界防御等同于以下范数裁剪方法：

![公式3](公式3.png)

+ **（弱）差分隐私**

首先裁剪更新（如上所述），然后添加高斯噪声。

# 实验

+ 数据集：EMNIST 数据集
+ 模型：具有两层卷积层，一层最大池层和两层密集层的五层卷积神经网络
+ 评估标准：任务准确率

![无约束攻击实验结果](无约束攻击实验结果.png)



![约束攻击实验结果](约束攻击实验结果.png)

注：（1）图中绿色的线代表后门任务的平均准确率，准确率越高代表后门攻击越有效。
（2）左边一列为固定频率攻击，右边一列为随机采样攻击

+ 固定频率攻击比随机采样攻击更有效
+ 后门攻击的成功很大程度上取决于对手的比例

![后门大小实验结果](后门大小实验结果.png)

+ 后门任务越多，适应恶意模型的难度就越大。

![范数边界和高斯噪音实验结果](范数边界和高斯噪音实验结果.png)

# 总结

我们在更现实的EMNIST数据集下研究了针对联合学习的后门攻击和防御。 在没有任何辩护的情况下，我们表明对手的表现很大程度上取决于当前对手的比例。 因此，为了获得合理的成功，需要有大量的对手。 令人惊讶的是，规范削减在很大程度上限制了已知后门攻击的成功。 此外，除了范数限幅外，加入少量的高斯噪声有助于进一步减轻敌方的影响。这就引出了几个有趣的问题。

更好的攻击和防御。 在范数有界的情况下，“预增强”的投影梯度下降的多次迭代可能不是单回合中最好的攻击方式。 实际上，对手可能会尝试直接制定满足规范界限的“最坏情况”模型更新（没有任何帮助）。 而且，如果攻击者知道他们可以进行多轮攻击，那么在规范的约束下可能会有更好的策略。 同样，应研究更高级的防御措施。

模型容量的影响。 可能影响后门攻击性能的另一个因素是模型容量，尤其是可以推测后门攻击会使用深度网络的备用容量（20）。 模型能力如何与后门攻击相互作用是一个有趣的问题，需要从理论和实践角度来考虑。