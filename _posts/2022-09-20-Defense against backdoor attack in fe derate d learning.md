---
layout: mypost
title: Defense against backdoor attack in fe derate d learning
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>Defense against backdoor attack in fe derate d learning</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>联邦学习中的后门攻击防御</th>
    </tr>
    <tr>
        <td>作者</td>
        <td></td>
    </tr>
    <tr>
        <td>来源</td>
        <td>会议名称 [会议等级]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2020 年 10 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>现有的防御方案不能很好地防御 FL 中的模型替换攻击和自适应后门攻击。</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td></td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>在模型收敛轮次和早期轮次防御后门攻击</td>
    </tr>
</table>

# 内容总结

# 主要贡献

1. 我们研究了 non-IID 联合设置中对大容量模型的后门攻击的特征，这表明可以利用冗余神经元来提高后门持久性并避免聚合后后门特征无效。
2. 我们提出了一种用于收敛轮攻击的具有相似性测量的新防御方案。 与现有的相似度度量方案不同，我们的方案是根据后门攻击的特点和脆弱性设计的，因此可以在FL中进行针对性的防御，时间复杂度更低，防御效果更好。
3. 我们将一种在深度学习中具有后门神经元激活的检测方法 (Wang等，2020) 移植到联邦学习中，并改进它以防御早期攻击。与Wang等人 (2020) 中的原始检测相比，我们的方法使服务器能够自动检测并从聚合模型中删除嵌入式后门，并具有更好的性能。
4. 基于 PyTorch 框架和联合平均 (Fed-Avg) 聚合规则的实验对后门攻击和我们的防御方案进行。结果表明，在收敛轮攻击下，与基准防御相比，我们的相似性测量防御在模型替换攻击（提高 25%）和自适应攻击（提高 67%）上都获得了最高的检测精度，而另一种具有后门神经元的防御激活可以去除后门并保持聚合模型在早轮攻击下的主要任务准确性。

# 预备知识

### 自适应后门攻击

将损失项 `$\ell_{ano}$` 引入模型损失函数 `$\ell_{model}$` 进行模型训练：

![公式7](公式7.png)

# 模型替换攻击的持久性

在模型替换攻击中，攻击者训练一个后门模型 `$w_j^{backdoor}$` &ensp;并将（6）中的恶意更新 `$\Delta_j^r$` 发送到服务器，旨在用近似后门模型 `$w_j^{backdoor}$` 替换全局模型 `$w_G^{r+1}$`。然而，在 FL 中多次聚合后，聚合模型的参数分布会发生变化，因此嵌入的后门可能会逐渐失效。

![模型替换攻击下聚合模型中后门的持久性](模型替换攻击下聚合模型中后门的持久性.png)

+ 在实验的早期轮次中注入的后门仍然保留在聚合模型中。
+ 无论我们在哪一轮发起模型替换攻击，在 non-IID 设置下，聚合模型的后门精度逐渐降低。

根据发起攻击的轮次，将 FL 中的后门攻击分为两类：收敛轮次攻击和早期轮次攻击。

# 用相似度度量防御收敛轮攻击

### 动机

在收敛轮生成的恶意更新 `$\Delta w_j^r$` 几乎与 `$(w_j^{backdoor}−W_G^r)$` 成正比。

### 方法

![PA-SM对收敛轮攻击的防御过程](PA-SM对收敛轮攻击的防御过程.png)

1. 在获得聚合模型之前添加一个预聚合，聚合所有客户端的更新；
2. 计算第 r 轮预聚合模型 `$w_p^r$`；
3. 计算余弦相似度 `cos(w_p^r-w_g^r, w_i^r)`；
4. 如果 `$cos(w_p^r-w_g^r, w_i^r) \geq \lambda$`，则第 i 个更新将被检测为恶意更新并从更新集中删除；否则，这是一个良性更新。

![具有相似性测量的检测结果](具有相似性测量的检测结果.png)

# 通过后门神经元激活防御早期攻击

### 动机

后门模型在某些坐标上表现出出乎意料的高神经元激活，因为它在后门输入上产生鲁棒的特征表示和错误分类。

### DF-TND

![公式8](公式8.png)

假设在分类任务中存在 `$N_1$` 个用于检测的随机种子模式和 `$K$` 个类别。对于每个类别`$k \in [K]$`，我们可以在第 `$k$` 个类别上获得局部模型的异常分数：

![公式9](公式9.png)

对于给定的阈值 `$T$`，如果 `$L_k > T$`，则该模型被检测为后门模型，并且第 `$k$` 个类别是攻击目标类别。

问题：（1）DF-TND 的效果取决于主任务精度和后门任务精度。（2）超参数 `$T$` 难以自动选择，这可能会影响检测效率。

### ACCDR

1. 使用 N 1 个随机模式通过求解优化问题得到它们的神经元表示
2. 计算第 k 个模型的异常分数 L k ( k = 1 , ..., m )
3. 计算聚合模型的异常分数
4. 计算所有异常分数的标准差，记为std(L 1  , L 2 , ... L m , L G) .

![ACCDR防御早轮攻击的过程](ACCDR防御早轮攻击的过程.png)


# 实验

+ 数据集：GTSRB 和 CIFAR10
+ 数据分布：non-IID
+ 训练模型：ResNet18

### 收敛轮次攻击下防御方案的性能分析

![收敛轮次攻击检测结果](收敛轮次攻击检测结果.png)

+ PA-SM 获得了最高的检测精度

### 早期轮次攻击下防御方案的性能分析

![早期攻击下各防御方案的性能比较](早期攻击下各防御方案的性能比较.png)

![低后门精度模型上ACCDR和DF-TND异常分数的比较](低后门精度模型上ACCDR和DF-TND异常分数的比较.png)

+ ACCDR 对后门模型的检测效果优于 DF-TND。

# 结论

在本文中，我们研究了 FL 中最新的后门攻击、模型替换攻击和自适应后门攻击。 根据后门攻击的持久性和特点，我们设计了PA-SM和ACCDR两种防御方案，分别在模型收敛轮和早期轮防御后门攻击。 与基准防御相比，PA-SM 在收敛轮攻击中可以获得最佳和最稳定的检测性能。 而且，PA-SM检测算法的时间复杂度最低。 由于攻击者可能会选择早轮攻击来规避 PA-SM，因此提出了 ACCDR 来检测和去除具有后门神经元激活的后门模型。 与差分隐私和对抗性训练相比，ACCDR 可以快速去除后门并保持聚合模型的主要任务准确性。 鉴于 ACCDR 的时间复杂度高，我们认为它更适合部署在 FL 的早期轮次中，而 PA-SM 是一种更方便的方案来防御模型收敛轮中的后门攻击。 在未来的工作中，我们将探索 FL 中的拜占庭后门攻击，其中可能会同时制作多个恶意模型来逃避防御。

# 参考

1. [百度](https://www.baidu.com){:target="_blank"}