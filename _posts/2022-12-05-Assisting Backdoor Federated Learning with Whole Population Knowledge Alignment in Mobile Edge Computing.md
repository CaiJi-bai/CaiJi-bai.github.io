---
layout: mypost
title: Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment in Mobile Edge Computing
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>Assisting Backdoor Federated Learning with Whole Population Knowledge Alignment in Mobile Edge Computing</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>在移动边缘计算中用全人口知识调整协助后门联邦学习</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Tian Liu, Xueyang Hu, Tao Shu</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>19th SECON 2022: Stockholm, Sweden [CCF 计算机网络 B 类会议]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2020 年 9 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>早期训练阶段的单发后门攻击较弱</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td></td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>利用信息泄漏来加强早期注入的单发后门攻击</td>
    </tr>
</table>

# 内容总结

# 主要贡献

1. 证明了 FL 模型和 CL 模型之间的聚合内权重差异的上限，并表明权重差异很小。
2. 利用上述近似和交叉熵的线性，提出了一种新颖的基于优化的整体种群分布推理攻击。
3. 我们为早期注入的单发后门攻击提出了一个初步阶段，该阶段通过减少正常客户端本地更新的稀释效应来提高攻击效果。
4. 在各种数据异构设置中进行了广泛的实验，以评估所提出的整体分布推理攻击的准确性、FL 全局模型收敛性的改进以及后门攻击的有效性。

# 威胁模型

1. 假设只有一个客户端具有发起后门攻击的能力，而其余客户端可以作为帮凶与 FL 模型进行多次交互。
2. 假设执行后门攻击的客户端具有翻转标签并设置自己的学习率和本地步骤的能力。
3. 其他人具有调整标签本地分布的能力，攻击者可以使用数据增强和采样技术来更改每个标签的样本数量。

# 权重差异（表征模型的性能）

![公式3和4](公式3和4.png)

+ （1）局部模型在 `$D_k$` 上的梯度和 CL 模型在 `$D$` 上的梯度之间的距离决定；（2）内部训练步数。
+ （1）`$D_k$` 和 `$D$` 之间的分布距离；（2）在 `$D_k$` 上计算的梯度与在 `$D$` 上计算的梯度之间的梯度距离。
+ FL 设置中的客户端可以从模仿整个群体的分布和梯度中受益，以实现更好的收敛行为（更快的收敛或更高的模型精度）。

# 我们的方法

### 预备阶段

+ 总体分布推理

![公式5](公式5.png)

估计 CL 模型更新

![公式6](公式6.png)

模型更新的分解

![公式7和8](公式7和8.png)

梯度估计

![算法1](算法1.png)

基于优化的全局分布估计

![公式9](公式9.png)

![算法2](算法2.png)

+ 辅助数据集构建

![算法3](算法3.png)

+ 训练并提交模型更新

### 攻击阶段

1. 制作中毒数据集
2. 训练模型
3. 缩放模型更新
4. 上传模型

# 实验

+ 数据集：MNIST
+ 分布：non-iid
+ 模型：两个卷积层和两个全连接层
+ 评估指标：总体分布推理攻击的准确性、通过总体分布获得的主要任务准确率增益、主要任务准确率、后门攻击成功率和寿命

# 实验结果

![总体分布推理的准确率](总体分布推理的准确率.png)

![主要任务准确率增益](主要任务准确率增益.png)

![主要任务准确率](主要任务准确率.png)

![后门攻击成功率](后门攻击成功率.png)

# 总结

1. 本文通过总体分布估计加速联邦学习的收敛，从而使早期后门攻击更加有效。

# 参考

1. [百度](https://www.baidu.com){:target="_blank"}