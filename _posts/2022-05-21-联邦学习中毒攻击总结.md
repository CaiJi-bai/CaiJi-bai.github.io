---
layout: mypost
title: 联邦学习中毒攻击总结
categories: [论文阅读]
---

# 中毒攻击

+ 目标攻击  
在有针对性的攻击中，对手希望模型只对一组选定的样本进行错误分类，对其在主要任务上的性能影响最小。这种有针对性的攻击也称为后门攻击。
+ 非目标攻击  
在非目标攻击中，对抗性任务是使模型收敛到次优最小值或使模型完全发散。 这种攻击也被称为收敛攻击，在某种程度上，它们很容易通过观察模型在验证数据上的准确性来检测。

# 中毒攻击

+ 数据中毒  
向节点添加恶意样本或错误样本，如标签反转
+ 模型中毒  
通过控制少数节点，向服务器更新错误或者恶意的参数，即可以达到影响全局模型性能与收敛的效果

# 后门攻击

+ 语义攻击
+ 木马攻击

# 后门攻击防御分类：
  1. 异常更新检测：FoolsGold，光谱异常检测，Flguard 等
  2. 鲁棒的联邦学习：裁剪模型权重和注入噪声，基于反馈的联邦学习，CRFL 等
  3. 后门模型恢复：在训练后修复后门全局模型

# 未来的研究方向：
+ 后门攻击：
  1. 针对纵向联邦学习的后门攻击
  2. 设计隐形的后门攻击
  3. 综合考虑环境因素，设计出更有效、更具物理实用性的攻击后门
  4. 触发器的选择
+ 后门攻击防御：
  1. 保持模型的准确性和保护隐私
  2. 为未来的其他任务（如语音、文本）设计防御策略
  3. 多触发后门攻击和无目标后门攻击的防御
  4. 修复后门模型