---
layout: mypost
title: 联邦学习中毒攻击总结
categories: [论文阅读]
---

# 中毒攻击

+ 目标攻击  
在有针对性的攻击中，对手希望模型只对一组选定的样本进行错误分类，对其在主要任务上的性能影响最小。这种有针对性的攻击也称为后门攻击。
+ 非目标攻击  
在非目标攻击中，对抗性任务是使模型收敛到次优最小值或使模型完全发散。 这种攻击也被称为收敛攻击，在某种程度上，它们很容易通过观察模型在验证数据上的准确性来检测。

# 中毒攻击

+ 数据中毒  
向节点添加恶意样本或错误样本，如标签反转
+ 模型中毒  
通过控制少数节点，向服务器更新错误或者恶意的参数，即可以达到影响全局模型性能与收敛的效果

# 后门攻击

+ 语义攻击
+ 木马攻击

# 后门攻击防御分类：
  1. 异常更新检测：FoolsGold，光谱异常检测，Flguard 等
  2. 鲁棒的联邦学习：裁剪模型权重和注入噪声，基于反馈的联邦学习，CRFL 等
  3. 后门模型恢复：在训练后修复后门全局模型

# 未来的研究方向：
+ 后门攻击：
  1. 针对纵向联邦学习的后门攻击
  2. 设计隐形的后门攻击
  3. 综合考虑环境因素，设计出更有效、更具物理实用性的攻击后门
  4. 触发器的选择
+ 后门攻击防御：
  1. 保持模型的准确性和保护隐私
  2. 为未来的其他任务（如语音、文本）设计防御策略
  3. 多触发后门攻击和无目标后门攻击的防御
  4. 修复后门模型

# 经典文献

# 攻击

### 数据中毒

1. [Attack of the tails: Yes, you really can backdoor federated learning（单触发器）](https://caiji-bai.github.io/posts/2022/05/24/Attack-of-the-Tails-Yes,-You-Really-Can-Backdoor-Federated-Learning.html){:target="_blank"}
2. [DBA: Distributed backdoor attacks against federated learning（多触发器）](https://caiji-bai.github.io/posts/2022/07/16/DBA-Distributed-Backdoor-Attacks-against-Federated-Learning.html){:target="_blank"}

### 模型中毒

1. [How to backdoor federated learning（模型替换）](https://caiji-bai.github.io/posts/2022/05/15/How-to-Backdoor-Federated-Learning.html){:target="_blank"}
2. [Analyzing federated learning through an adversarial lens](https://caiji-bai.github.io/posts/2022/07/05/Analyzing-Federated-Learning-through-an-Adversarial-Lens.html){:target="_blank"}
3. [Local model poisoning attacks to Byzantine-robust federated learning](https://caiji-bai.github.io/posts/2022/06/14/Local-Model-Poisoning-Attacks-to-Byzantine-Robust-Federated-Learning.html){:target="_blank"}

# 防御

### 异常更新检测

1. [Mitigating sybils in federated learning poisoning（FoolsGold）](https://caiji-bai.github.io/posts/2022/04/04/Mitigating-Sybils-in-Federated-Learning-Poisoning.html){:target="_blank"}
2. [Learning to detect malicious clients for robust federated learning（降维-变分自动编码器-光谱异常检测）](https://caiji-bai.github.io/posts/2022/06/28/Learning-to-Detect-Malicious-Clients-for-Robust-Federated-Learning.html){:target="_blank"}
3. Flguard: Secure and private federated learning（综合运用多种技术-两层防御-适用多触发）
4. [Data Poisoning Attacks Against Federated Learning Systems（降维-PCA）](https://caiji-bai.github.io/posts/2022/07/09/Data-Poisoning-Attacks-Against-Federated-Learning-Systems.html){:target="_blank"}

### 健壮的联合训练

1. [Can you really backdoor federated learning?（范数裁剪+噪声）](https://caiji-bai.github.io/posts/2022/05/21/Can-You-Really-Backdoor-Federated-Learning.html){:target="_blank"}
2. [BaFFLe: Backdoor detection via feedback-based federated learning（反馈）](https://caiji-bai.github.io/posts/2022/07/19/BaFFLe-Backdoor-Detection-via-Feedback-based-Federated-Learning.html){:target="_blank"}
3. CRFL: Certiﬁably robust federated learning against backdoor attacks（认证）
4. [Meta Federated Learning（修改协议过程-分组聚合）](https://caiji-bai.github.io/posts/2022/07/12/Meta-Federated-Learning.html){:target="_blank"}
5. Secure Partial Aggregation: Making Federated Learning More Robust for Industry 4.0 Applications（修改协议过程-限制模型更新上传比例）
6. FLAME: Taming Backdoors in Federated Learning（综合运用多种技术）

### 后门模型恢复

1. Mitigating backdoor attacks in federated learning（训练后防御）