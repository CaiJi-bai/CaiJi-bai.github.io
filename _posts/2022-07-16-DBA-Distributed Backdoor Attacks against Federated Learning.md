---
layout: mypost
title: DBA-Distributed Backdoor Attacks against Federated Learning
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>DBA: Distributed Backdoor Attacks against Federated Learning</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>针对联邦学习的分布式后门攻击</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Chulin Xie, Keli Huang, Pin-Yu Chen, Bo Li</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>8th ICLR 2020: Addis Ababa, Ethiopia [深度学习顶级会议]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2020 年 4 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>当前的攻击并没有充分利用 FL 的分布式学习方法，因为它们将相同的全局触发模式嵌入到所有敌对方。</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td>了解分布式后门攻击</td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>多触发器后门攻击</td>
    </tr>
</table>

# 内容总结

# 分布式后门攻击（DBA）与集中式后门攻击（CBA）

1. 分布式后门攻击是指有多个恶意客户端，本地触发器被注入到多个恶意客户端的本地训练数据集中，所有恶意客户端都有相同的后门任务。
2. 集中式后门攻击是指全局触发器被注入到一个客户端的本地训练数据集。

![FL上的集中式和分布式后门攻击概述](FL上的集中式和分布式后门攻击概述.png)

# 威胁模型

### 攻击者能力

基于 Kerckhoffs 的理论（Shannon，1949），我们认为这里的强攻击者完全控制其局部训练过程，例如后门数据注入和更新局部训练超参数，包括E和lr。这种场景非常实用，因为每个本地数据集通常由一个本地方拥有。然而，攻击者无法影响中央服务器的权限，例如更改聚合规则，也无法篡改其他方的训练过程和模型更新。

### 攻击目标

联邦学习目标：

`$$min_{\omega\in R^d}[F(\omega):=\frac{1}{N}\sum_{i=1}^Nf_i(\omega)]$$`

在具有局部数据集 `$D_i$` 和目标标签 `$\tau$` 的第 t 轮中，攻击者 i 的对抗目标是：

![公式2](公式2.png)

分布式后门攻击目标：

![公式3](公式3.png)

其中 `$R$` 函数用于将干净的数据植入触发器从而将其转换成后门数据，`$\phi_i^*$` 是全局触发器在每个局部任务上的分解，`$\tau$` 是目标标签。

### 分布式后门攻击因素

![触发器因素](触发器因素.png)

1. 触发器大小 TS：局部分布式触发器的像素列数（即宽度）。
2. 触发器间隔 TG：Gapx和Gapy的距离，分别代表左右的距离，以及上、下的局部触发。
3. 触发位置 TL：（Shiftx，Shifty）是触发图案与左上像素的偏移量。
4. 缩放 `$\gamma$`：攻击者使用（Bagdasaryan et al.，2018）中定义的缩放参数 `$\gamma=\eta/N$` 来放大恶意模型权重。例如，假设第 `$i$` 个恶意局部模型为 `$X$`。将提交的新局部模型 `$L_i^{t+1}$` 计算为 `$L_i^{t+1}=\gamma(X-G^t)+G^t$`。
5. 中毒率 r：该比率控制每个训练批次添加的后门样本的比例。 需要注意的是，在进行直观攻击时，较大的 r 应该是更可取的，并且在干净的数据准确性和攻击成功率之间存在权衡，但是一旦模型变得无用，太大的 r 也会损害攻击效果。
6. 中毒间隔 I：两个中毒步骤之间的循环间隔。例如，I = 0 表示所有本地触发器都嵌入在一个轮次中，而 I = 1 表示本地触发器嵌入在连续轮次中。
7. 数据分布：FL 通常假定参与方之间的数据分布是 non-iid。在这里，我们使用具有不同超参数 `$\alpha$` 的 Dirichlet 分布来按照（Bagdasaryan et al.，2018）中的设置生成不同的数据分布。

# 步骤

1. 首先需要确定触发因素，包括触发器大小、触发器之间的间隔、触发器放置的位置、对恶意模型参数进行放大的比例（即恶意模型为 `$X$`，而提交的本地模型为`$\gamma(X-G^t)+G^t$`）、对数据投毒比例和投毒间隔。
2. 对每一个恶意客户端，确定其分布式后门目标。
3. 使用交叉熵作为具体的损失函数，对模型参数进行训练。

# 实验

+ 数据集：Lending Club Loan Data, MNIST, CIFAR-10 and Tiny-imagenet
+ 数据分布：Non-IID
+ 训练模型：SGD


### 分布式后门攻击 V.S. 集中式后门攻击

+ 攻击场景：发攻击 (Attack A-M) 和单发攻击 (Attack A-S)
+ Attack A-M 研究成功注入后门的难易程度，而 Attack A-S 研究后门效应减弱的速度。

![Attack A-M 和 A-S](Attack A-M 和 A-S.png)

+ 在 Attack A-M 中，DBA 的攻击成功率始终高于集中式攻击
+ DBA 可以导致全局触发器的高攻击成功率，即使它的一些本地触发器仅获得低攻击成功率。
+ 在 Attack A-S 中，DBA 和集中式攻击在所有数据集中执行完整的后门后都达到了很高的攻击成功率
+ 集中式攻击在局部触发和全局触发中的攻击成功率比 DBA 下降得更快，这表明 DBA 产生了更持久的攻击。

### 分布式攻击的鲁棒性

+ 聚合类型：RFA 和 FoolsGold

![两种鲁棒强化学习方法的攻击有效性比较](两种鲁棒强化学习方法的攻击有效性比较.png)

+ DBA 的攻击性能和 RFA 下的集中式攻击
+ DBA 攻击者提交的恶意更新在所有数据集中的距离都小于集中式攻击者的更新距离
+ DBA也优于FoolsGold下的集中式攻击。
+ 分布式攻击者的权重之和可能大于集中式攻击者。

### 通过特征可视化和特征重要性进行解释

![特征分析结果](特征分析结果.png)

+ 我们发现每个局部触发的图像本身都是一个弱攻击，因为它们都不能改变预测（没有注意嵌入触发器的左上角）。 但是，当组合在一起作为全局触发器时，后门图像被分类为“2”（目标标签），我们可以清楚地看到注意力被拖到了触发器位置。
+ 基于软决策树，不重要的特征对于中毒后的预测变得非常重要。

# 分布式后门攻击触发因素分析

### scale 的影响

![scale的影响](scale的影响.png)

+ 模型架构越复杂（在 Tb.1 中），随着 γ 的增加，主要准确度的下降越明显
+ 更大的尺度因子减轻了中央服务器对DBA的平均影响，从而产生了更大的影响力和抵抗攻击性能，但也导致三个图像数据集的主要攻击精度下降。

### 触发器位置的影响

![触发器位置的影响](触发器位置的影响.png)

+ U形曲线。这是因为图像的中间部分通常包含主要对象。这些区域的DBA很难成功，并且会很快被遗忘，因为这些像素是主要精度的基础。

### 触发器间隙的影响

![触发器间隙的影响](触发器间隙的影响.png)

+ DBA-ASR和DBA-ASR-t的曲线中间有明显下降

### 触发器大小的影响

![触发器大小的影响](触发器大小的影响.png)

+ 在A-S攻击下，触发太小的后门攻击是无效的。

### 中毒间隔的影响

![中毒间隔的影响](中毒间隔的影响.png)

+ 局部触发效果可以持续很长时间，并有助于全局触发的攻击性能。

### 中毒率的影响

![中毒率的影响](中毒率的影响.png)

+ 中毒数据越多，后门性能越好。然而，过大的毒药比率意味着攻击者会增加低精度局部模型的权重，从而导致全局模型在主任务中失败。

### 数据分布的影响

+ 在不同的数据分布下，DBA-ASR 是稳定的，表明了 DBA 的实用性和鲁棒性。

# 总结

通过在包括 LOAN 和三个图像数据集在内的不同数据集上的大量实验，我们证明了在标准 FL 中，我们提出的 DBA 比集中式后门攻击更持久和有效。