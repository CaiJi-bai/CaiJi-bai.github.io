---
layout: mypost
title: DBA-Distributed Backdoor Attacks against Federated Learning
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>DBA: Distributed Backdoor Attacks against Federated Learning</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>针对联邦学习的分布式后门攻击</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Chulin Xie, Keli Huang, Pin-Yu Chen, Bo Li</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>8th ICLR 2020: Addis Ababa, Ethiopia [深度学习顶级会议]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2020 年 4 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>当前的攻击并没有充分利用 FL 的分布式学习方法，因为它们将相同的全局触发模式嵌入到所有敌对方。</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td>了解分布式后门攻击</td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>多触发器后门攻击</td>
    </tr>
</table>

# 内容总结

# 分布式后门攻击（DBA）与集中式后门攻击（CBA）

利用 FL 聚合来自本地参与方的分散信息以训练共享模型的能力，本文提出了针对 FL 的分布式后门攻击（DBA）。给定与集中攻击相同的全局触发模式，DBA 将其分解为局部模式，并将其分别嵌入到不同的敌对方。

1. 分布式后门攻击是指将全局触发器分解为多个局部触发器，被注入到多个恶意客户端的本地训练数据集中，所有恶意客户端都有相同的后门任务。
2. 集中式后门攻击是指将全局触发器注入到所有恶意客户端的本地训练数据集。

![FL上的集中式和分布式后门攻击概述](FL上的集中式和分布式后门攻击概述.png)

# 威胁模型

### 攻击者能力

1. 基于 Kerckhoffs 理论，我们认为这里的强攻击者完全控制其局部训练过程，例如后门数据注入和更新局部训练超参数，包括 `$E$` 和 `$l_r$`。
2. 攻击者无法影响中央服务器的权限，例如更改聚合规则，也无法篡改其他方的训练过程和模型更新。

### 攻击目标

联邦学习目标（有限和优化）：

`$$min_{\omega\in R^d} [F(\omega):=\frac{1}{N}\sum_{i=1}^Nf_i(\omega)]$$`

在具有局部数据集 `$D_i$` 和目标标签 `$\tau$` 的第 `$t$` 轮中，攻击者 `$i$` 的对抗目标是：

![公式2](公式2.png)

其中 `$R$` 函数用于将干净的数据植入触发器从而将其转换成后门数据，`$\phi$` 是触发器模式（TS,TG,TL），`$\tau$` 是目标标签。

分布式后门攻击目标（将集中式攻击公式分解为 `$M$` 个分布式子攻击问题）：

![公式3](公式3.png)

其中 `$R$` 函数用于将干净的数据植入触发器从而将其转换成后门数据，`$\phi_i^*$` 是全局触发器在每个局部任务上的分解，`$\tau$` 是目标标签。

### 分布式后门攻击因素

![触发器因素](触发器因素.png)

1. 触发器大小 TS：局部分布式触发器的像素列数（即宽度）。
2. 触发器间隔 TG：Gapx 和 Gapy 的距离，分别代表左右的距离，以及上、下的局部触发。
3. 触发位置 TL：（Shiftx，Shifty）是触发图案与左上像素的偏移量。
4. 缩放 `$\gamma$`：攻击者使用（Bagdasaryan et al.，2018）中定义的缩放参数 `$\gamma=\eta/N$` 来放大恶意模型权重。例如，假设第 `$i$` 个恶意局部模型为 `$X$`。将提交的新局部模型 `$L_i^{t+1}$` 计算为 `$L_i^{t+1}=\gamma(X-G^t)+G^t$`。
5. 中毒率 r：该比率控制每个训练批次添加的后门样本的比例。 需要注意的是，在进行直观攻击时，较大的 r 应该是更可取的，并且在干净的数据准确性和攻击成功率之间存在权衡，但是一旦模型变得无用，太大的 r 也会损害攻击效果。
6. 中毒间隔 I：两个中毒步骤之间的循环间隔。例如，I = 0 表示所有本地触发器都嵌入在一个轮次中，而 I = 1 表示本地触发器嵌入在连续轮次中。
7. 数据分布：FL 通常假定参与方之间的数据分布是 non-iid。在这里，我们使用具有不同超参数 `$\alpha$` 的 Dirichlet 分布来按照（Bagdasaryan et al.，2018）中的设置生成不同的数据分布。

# 步骤

1. 首先需要确定触发因素，包括触发器大小、触发器之间的间隔、触发器放置的位置、对恶意模型参数进行放大的比例（即恶意模型为 `$X$`，而提交的本地模型为`$\gamma(X-G^t)+G^t$`）、对数据投毒比例和投毒间隔。
2. 对每一个恶意客户端，确定其分布式后门目标。
3. 使用交叉熵作为具体的损失函数，对模型参数进行训练。

# 实验

+ 数据集：Lending Club Loan Data, MNIST, CIFAR-10 and Tiny-imagenet
+ 数据分布：Non-IID

### 分布式后门攻击 V.S. 集中式后门攻击

+ 攻击场景：多发攻击 (Attack A-M) 和单发攻击 (Attack A-S)
+ Attack A-M 研究成功注入后门的难易程度，而 Attack A-S 研究后门效应减弱的速度。

![Attack A-M 和 A-S](Attack A-M 和 A-S.png)

+ 在 Attack A-M 中，DBA 的攻击成功率始终高于集中式攻击，收敛速度也更快。
+ 全局触发器的攻击成功率高于任何本地触发器，即使全局触发器实际上从未出现在任何本地训练数据集中。全局触发器在攻击性能上比局部触发器收敛得更快。
+ 集中式攻击者嵌入了整个模式，因此其对任何本地触发器的攻击成功率都很低。
+ **DBA 可以导致全局触发器的高攻击成功率，即使它的一些本地触发器仅获得低攻击成功率。（对 FL 的集中式攻击效率低下）**
+ 在 Attack A-S 中，DBA 和集中式攻击在所有数据集中执行完整的后门后都达到了很高的攻击成功率
+ 集中式攻击在局部触发和全局触发中的攻击成功率比 DBA 下降得更快，这表明 DBA 产生了更持久的攻击。

### 分布式攻击的鲁棒性

+ 聚合类型：RFA 和 FoolsGold

![两种鲁棒强化学习方法的攻击有效性比较](两种鲁棒强化学习方法的攻击有效性比较.png)

+ DBA 优于集中式攻击。
+ DBA 攻击者提交的恶意更新在所有数据集中的距离都小于集中式攻击者的更新距离，这有助于他们更好地绕过防御。
+ 尽管由于 DBA 攻击者与后门目标标签的相似性，FoolsGold 为其分配了较小的聚合权重，但 DBA 仍然更成功。分布式攻击者的权重之和可能大于集中式攻击者。

### 通过特征可视化和特征重要性进行解释

![特征分析结果](特征分析结果.png)

+ 我们发现每个局部触发的图像本身都是一个弱攻击，因为它们都不能改变预测（没有注意到左上角嵌入的触发器）。 但是，当组合在一起作为全局触发器时，后门图像被分类为“2”（目标标签），我们可以清楚地看到注意力被拖到了触发器位置。证明了 DBA 的隐秘性。
+ 基于软决策树，不重要的特征对于中毒后的预测变得非常重要。

# 分布式后门攻击触发因素分析

在 Attack A-S 中，DBA-ASR 表示攻击成功率，而 Main-Acc 表示嵌入最后一个分布式本地触发器时全局模型的准确性。DBA-ASR-t 揭示了持久性，是一个完整的 DBA 执行后 t 轮的攻击成功率。Main-Acc-t 是 t 轮后的主要任务准确率。

### scale 的影响

![scale的影响](scale的影响.png)

+ 放大比例因子会增加 DBA-ASR 和 DBA-ASR-t，并缩小它们之间的差距。
+ 模型架构越复杂，随着 `$\gamma$` 的增加，主要准确度的下降越明显。（破坏参数）
+ 更大的尺度因子减轻了中央服务器对 DBA 的平均影响，从而产生了更大的影响力和抵抗攻击性能，但也导致三个图像数据集的主要攻击精度下降。（容易被检测到）

### 触发器位置的影响

![触发器位置的影响](触发器位置的影响.png)

+ U 形曲线。这是因为图像的中间部分通常包含主要对象。这些区域的DBA很难成功，并且会很快被遗忘，因为这些像素是主要精度的基础。

### 触发器间隙的影响

![触发器间隙的影响](触发器间隙的影响.png)

+ 间隔最大，DBA-ASR 和 DBA-ASR-t 在图像数据集中都较低。原因：局部卷积操作和局部触发器之间的距离过大导致全局模型无法识别全局触发器。
+ 图 a 中，DBA-ASR 和 DBA-ASR-t 的曲线中间有明显下降

### 触发器大小的影响

![触发器大小的影响](触发器大小的影响.png)

+ 在图像数据集中，较大的触发大小给出较高的 DBA-ASR 和 DBA-ASR-T。
+ 使用过大的触发器几乎没有增益
+ 在A-S攻击下，触发太小的后门攻击是无效的。

### 中毒间隔的影响

![中毒间隔的影响](中毒间隔的影响.png)

+ 局部触发效果可以持续很长时间，并有助于全局触发的攻击性能。

### 中毒率的影响

![中毒率的影响](中毒率的影响.png)

+ 中毒数据越多，后门性能越好。然而，过大的毒药比率意味着攻击者会增加低精度局部模型的权重，从而导致全局模型在主任务中失败。
+ DBA最好在其局部训练中保持隐蔽性方法是使用合理的毒物比率，同时保持干净数据的准确性。

### 数据分布的影响

+ 在不同的数据分布下，DBA-ASR 是稳定的，表明了 DBA 的实用性和鲁棒性。

# 总结

通过在包括 LOAN 和三个图像数据集在内的不同数据集上的大量实验，我们证明了在标准 FL 中，我们提出的 DBA 比集中式后门攻击更持久和有效。