---
layout: mypost
title: BaFFLe-Backdoor Detection via Feedback-based Federated Learning
categories: [论文阅读]
---

<table border="1">
    <tr>
        <th>论文英文名字</th>
        <th>BaFFLe: Backdoor Detection via Feedback-based Federated Learning</th>
    </tr>
    <tr>
        <th>论文中文名字</th>
        <th>基于反馈的联邦学习的后门检测</th>
    </tr>
    <tr>
        <td>作者</td>
        <td>Sébastien Andreina, Giorgia Azzurra Marson, Helen Möllering</td>
    </tr>
    <tr>
        <td>来源</td>
        <td>41st ICDCS 2021: Washington DC, USA [CCF 计算机体系结构/并行与分布计算/存储系统 B 类会议]</td>
    </tr>
    <tr>
        <td>年份</td>
        <td>2021 年 7 月</td>
    </tr>
    <tr>
        <td>作者动机</td>
        <td>现有的缓解 FL 中毒攻击解决方案要么被自适应攻击所规避，要么忽视了客户端的隐私，要么需要对现有的 FL 算法进行大量的计算修改。寻求一种不会破坏客户数据隐私并且与标准 FL 算法完全兼容的防御</td>
    </tr>
    <tr>
        <td>阅读动机</td>
        <td></td>
    </tr>
    <tr>
        <td>创新点</td>
        <td>利用参与 FL 过程的众多客户来改进一项任务，否则这项任务由单个实体执行是次优的。</td>
    </tr>
</table>

# 内容总结

# 威胁模型

1. 攻击者控制参与 FL 过程的多个客户端，并且这些客户端可以任意偏离 FL 协议（即，它们是拜占庭的）。
2. 我们假设在每次训练迭代中，大多数客户都是诚实的：在所选的 `$n$` 个客户中，多达 `$n_M$` 可能是恶意的，其中 `$n_M < \frac{n}{2}$`。

# 反馈回路

### 概述

![BaFFLe的高级设计](BaFFLe的高级设计.png)

### 设计

![算法1](算法1.png)

1. 获得用户局部更新，聚合得到当前待检测的全局模型。服务器获取 `$n$` 个用户的更新，聚合后得到当前的全局模型 `$G^r$`。
2. 确定每一轮的拒绝阈值。由于期望每一轮的全局模型的精度都比上一轮的全局模型有所提高，因此根据最近几轮的全局模型在服务器的测试集上的预测结果确定这一轮的拒绝阈值，用于客户端判断全局模型是否可疑。
3. 选择客户端。服务器随机选择 `$n$` 个客户端，将当前的全局模型以及拒绝阈值发送给客户端。
4. 客户端使用本地数据集进行验证。客户端验证全局模型，并根据拒绝阈值向服务器报告当前全局模型是否可疑。
5. 确定仲裁阈值 `$q$` 使得是服务器拒绝当前全局模型需要的报告可疑的客户端的最少数量。既要保证不能因为恶意客户端的恶意误报而导致拒绝真正的模型（即 `$n_M < q$`），也要保证能让诚实的客户端拒绝中毒模型（即 `$n_M < n-q$`），其中 `$n_M$` 为恶意客户端的最大数量。当然考虑到诚实客户端也会有误判的情况，所以还要依据经验考虑到误判率 `$\rho$`。
6. 服务器判断全局模型是否为中毒模型。如果有大于等于仲裁阈值 `$q$` 的验证客户端认为该模型可疑，则服务器拒绝接受这一轮的全局更新，并令这一轮的全局模型为上一轮的全局模型 `$G^{r-1}$`，继续进行下一轮的更新。