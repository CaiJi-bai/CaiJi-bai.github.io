---
layout: mypost
title: 联邦学习后门攻击总结
categories: [论文阅读]
---

# 后门攻击的定义

在联邦学习中，后门攻击是意图让模型对具有某种特定特征的数据做出错误的判断，但模型不会对主任务产生影响。

在联邦学习场景下进行后门攻击会比较困难，一个原因就是在服务端进行聚合运算时，平均化之后会很大程度消除恶意客户端模型的影响，另一个原因是由于服务端的选择机制，因为并不能保证被攻击者挟持的客户端在每一轮都能被选取，从而降低了被后门攻击的风险。

# 后门攻击策略

带有后门攻击行为的联邦学习，其客户端可以分为恶意客户端和正常客户端。不同类型的客户端，其本地训练策略各不相同。

### 正常客户端训练

正常客户端的训练算法如下，其执行过程就是常规的梯度下降过程。

正常客户端 i 的第 t 轮的训练算法：

---

input:&ensp;全局模型 `$G^t$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;学习率: `$\eta$`;  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;本地迭代次数: `$E$`;  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;每一轮训练的样本大小: `$B$`;  
output: 返回模型更新：`$\Delta_i^t$`

利用服务端下发的全局模型参数 `$G^t$`，更新本地模型 `$L_i^t$`：`$L_i^t \leftarrow G^t$`  
for 对每一轮的迭代 i = 1, 2, 3, ..., E，执行下面的操作 do  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;将本地数据切分为 |B| 份数据 B  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;for 对每一个 batch `$b \in B$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;执行梯度下降：`$L_i^t \leftarrow L_i^t-\eta\Delta\ell(L_i^t;b)$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;计算更新：`$\Delta_i^t=L_i^t-G^t$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;end  
end  

---

### 恶意客户端训练

对于恶意客户端的本地训练，主要体现在两个方面：损失函数的设计和上传服务端的模型权重。

+  对于损失函数的设计，恶意客户端训练的目标，一方面是保证在正常数据集和被篡改毒化的数据集中都取得较好的性能；另一方面是保证本地训练的模型与全局模型之间的距离尽量小（距离越小，被服务端判断为异常模型的概率就越小）。 
+  对于上传服务端的模型权重，根据以下公式：`$L_m^{t+1} \approx \frac{n}{\eta}(X-G^t)+G^t$` 可以看出，通过增大异常客户端 `$m$` 的模型权重，使其在后面的聚合过程中，对全局模型的影响和贡献尽量持久。

恶意客户端 j 的第 t 轮的训练算法:

---

input:&ensp;全局模型 `$G^t$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;学习率: `$\eta$`;  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;本地迭代次数: `$E$`;  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;每一轮训练的样本大小: `$B$`;  
output: 返回模型更新：`$\Delta_j^t$`

利用服务端下发的全局模型参数 `$G^t$`，更新本地模型 `$L_j^t$`：`$L_j^t \leftarrow G^t$`  
损失函数：`$\ell = \ell_{class_loss} + \ell_{distance_loss} / \ell_{ano_loss}$`  
for 对每一轮的迭代 i = 1, 2, 3, ..., E，执行下面的操作 do  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;将本地数据切分为 |B| 份数据 B  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;for 对每一个 batch `$b\in B$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;数据集 `$b=\left\{ D_{cln}^m, D_{adv}^m \right\}$` 中包含正常的数据集 `$D_{cln}^m$` 和被篡改毒化的数据集 `$D_{adv}^m $`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;执行梯度下降：`$L_j^t \leftarrow L_j^t-\eta\Delta\ell(L_j^t;b)$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;计算更新：`$\Delta_i^t=L_j^t-G^t$`  
&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;end  
end  

---

# 方向

联邦学习中后门攻击的防御

# 问题

1. 如何区分后门更新和良性更新？（找到一个特征或现象，然后构建一个防御框架）
2. 改进机器学习学习中后门防御的方法，使其适用于联邦学习中后门攻击的防御？
3. 防御最新的后门攻击？
4. 设计比现有防御更好的方法？

# 其他

1. 如何设计一个高效的触发器？